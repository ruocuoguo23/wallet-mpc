# 安全素数生成优化方案

## 背景
原有的 `generate_safe_prime` 算法采用简单的试除法（Trial Division），即生成一个随机数，然后依次用小素数进行模运算检查。如果通过检查，再进行昂贵的 Miller-Rabin 素性测试。

存在的问题：
1. **试除效率低**：对于每一个随机候选数，都要进行大量的模运算（大数除以小数）。
2. **筛选不充分**：原算法只检查了 `2x+1` 是否被小素数整除，没有检查 `x` 本身是否被小素数整除。
3. **利用率低**：虽然缓存了 200,000 个小素数，但由于算法效率限制，实际只使用了前 135 个。

## 优化方案：Eratosthenes 筛法（Sieving）

我们采用筛法来批量处理候选数，而不是逐个生成和检查。

### 算法流程

1. **生成基数**：生成一个随机的大奇数 `base`。
2. **建立筛表**：创建一个布尔数组 `sieve`（例如大小为 100,000），代表 `base, base+2, base+4, ...` 等一系列候选数。
3. **批量筛选**：
   对于每一个小素数 `p`（使用前 50,000 个或更多）：
   - 计算 `base % p` 的余数。
   - 找出筛表中所有满足 `(base + 2k) % p == 0` 的位置 `k`，标记为合数（`x` 是合数）。
   - 找出筛表中所有满足 `(2(base + 2k) + 1) % p == 0` 的位置 `k`，标记为合数（`2x+1` 是合数）。
   
   这一步极大地减少了昂贵的大数除法操作。对于每个小素数，我们只需要做一次大数取模，然后就是简单的数组索引标记。

4. **素性测试**：
   遍历筛表，对于未被标记的候选数 `candidate = base + 2k`：
   - 进行 Miller-Rabin 测试检查 `candidate` 是否为素数。
   - 如果通过，检查 `2*candidate + 1` 是否为素数。
   - 如果都通过，则找到了安全素数 `p = 2*candidate + 1` 并返回 `p`（注意：必须返回 `p` 而不是 `candidate`，否则会导致位数不足）。

### 性能提升分析

1. **减少大数运算**：将 `N` 次大数取模减少为 `1` 次大数取模 + `N` 次小整数加法。
2. **更强的过滤**：同时过滤了 `x` 和 `2x+1` 的小因子，大幅减少了进入 Miller-Rabin 测试的候选数数量。
3. **充分利用缓存**：可以高效地使用成千上万个小素数进行筛选（例如 50,000 个），而不会像试除法那样导致性能线性下降。

### 参数调整

- **筛选数量 (amount)**：从 135 增加到 50,000。这利用了扩展的 `SMALL_PRIMES` 缓存，极大地提高了筛选密度。
- **筛表大小 (SIEVE_SIZE)**：设置为 100,000。这意味着每一轮随机生成可以检查 100,000 个候选数，大大提高了命中率。

## 进一步优化：连续筛法（Continuous Sieving）

为了进一步提高效率，我们引入了连续筛法（Moving Window Sieve）。

### 核心思想
原有的筛法在每一轮随机生成 `base` 后，都需要对所有小素数进行大数取模运算 `base % p`。当 `amount` 很大（如 200,000）时，这 200,000 次大数取模成为了新的瓶颈。

连续筛法通过维护一个移动的窗口，避免了重复的大数取模：
1. **初始化**：只在第一次生成 `base` 时计算所有小素数的偏移量 `offsets`。
2. **筛窗口**：利用 `offsets` 直接在当前窗口 `[base, base + 2*SIEVE_SIZE)` 中标记合数。
3. **移动窗口**：当当前窗口筛完后，直接将 `base` 增加 `2*SIEVE_SIZE`，并更新 `offsets`，无需重新进行大数取模。
4. **重置**：只有当 `base` 增长到超过目标位数时，才重新生成随机数并重置偏移量。

### 参数调整
- **amount**: 200,000（使用全部缓存的小素数）。
- **SIEVE_SIZE**: 400,000（增大窗口大小以分摊偏移量更新的开销，同时适配 L3 缓存）。

这种方法将大数运算的开销分摊到了无数个窗口中，使得筛选过程几乎完全由内存访问和简单整数加法构成，极大地提高了吞吐量。


